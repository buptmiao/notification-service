## AI 使用说明

该项目主要借助的AI 工具为 kiro + claude code，包括需求分析，给定技术选型下的整体系统设计，制定实现计划，编码任务，和自动化测试等。

### 系统边界

**本系统解决的问题：**
- 统一的通知发送接口，屏蔽不同供应商 API 的差异
- 可靠投递保证（至少一次语义）
- 自动重试与失败处理
- 通知状态追踪与查询
- 按供应商维度的监控指标

**本系统不解决的问题：**
- 外部供应商 API 的速率限制（由供应商自行处理）
- 通知内容的业务逻辑验证（由业务系统负责）
- 外部 API 的响应内容解析（业务系统不关心返回值）
- 通知的幂等性保证（由业务系统通过唯一业务 ID 实现）

### 投递语义

采用 **至少一次（At-Least-Once）** 投递语义：
- 通知在被确认投递成功前会持续重试
- 外部系统需要具备幂等处理能力
- 选择原因：在"丢失通知"和"重复通知"之间，业务场景更倾向于接受重复

### 外部系统失败或长期不可用处理

当外部系统长期不可用时：
1. 通知会持续重试直到达到最大重试次数（默认 5 次）
2. 重试间隔采用指数退避：1s → 2s → 4s → 8s → 16s（加随机抖动）
3. 超过最大重试次数后，状态标记为 FAILED
4. 运维人员可以通过管理接口手动重试或取消
5. 系统通过监控指标（按 vendor_name 维度）暴露失败情况，便于及时发现问题

**为什么不无限重试？**
- 无限重试会导致队列积压，影响其他正常通知的处理
- 长期不可用通常意味着需要人工介入（如供应商 API 变更、网络配置问题）

### 取舍
1. AI: 引入优先级队列，并按照通知优先级进行分流
Justification: 在没有流量压力和优先级需求之前，我们视所有消息为同等优先级，过早设计优先级会引入系统和业务的复杂度。
2. AI: 当高并发情况下，notification service 需要实现限流器来保护外部系统接口，防止压垮。
Justification: 我们可以根据通知服务的capacity为我们的通知服务实现限流，但是不必为了防止流量过大压垮外部系统而设计限流器。外部系统应该根据自身的处理能力设置限流逻辑，而不必放在内部通知系统中，除非另有需求（如有预算限制或额外协议）。另一方面，不合理的限流阈值设计可能会影响notification service 的可靠性。
3. AI: 死信队列的设计，当消息经过最大重试次数之后仍然失败之后，AI给的解决方案是将notification 标记为failed，并同时发送到dlq。
Justification: 此为过度设计，当通知超过最大重试次数时，只在 MongoDB 中标记为 FAILED就足够了，不需要发送到 RabbitMQ DLQ， MongoDB 是唯一的 source of truth。
4. AI: 给出了监控metric系统，但是只包含粗粒度的metric
Justification: 需要按照vendor name 维度观测通知投递的状态并设置告警，从而及时发现并定位系统中的问题。这对提高服务可用性和可靠性至关重要。可以扩展不同使用场景的维度，进一步提高可观测行。
5. AI: 除了HTTP API 之外，提供基于消息队列的 api，让系统能够根据自身处理能力来处理内部请求
Justification: 确实在流量足够大的时候是有必要的，突发的大流量（对通知系统来说，突发流量很常见）可能会增加数据库的写入压力导致数据库异常。使用消息队列可以起到削峰填谷的作用。题目要求对内提供统一、标准化的 HTTP API，这可以支撑一般流量压力。


### 组件选型

| 组件 | 选择 | 原因 |
|------|------|------|
| 消息队列 | RabbitMQ | 支持延迟消息（用于重试），成熟稳定 |
| 持久化存储 | MongoDB | 文档模型适合存储灵活的通知数据 |

**不使用时的替代方案：**
- 如果没有 RabbitMQ：可使用数据库轮询 + 定时任务，但会增加数据库压力
- 如果没有 MongoDB：可使用 PostgreSQL，但需要更严格的 schema 设计


## 系统演进规划

### 当前 V1 版本的设计边界

V1 版本聚焦于核心功能的可靠实现：
- 单实例部署，RabbitMQ 单节点
- 同步持久化后再入队
- 简单的指数退避重试策略
- 基础的 Prometheus 指标

### 流量增长时的演进方向

**阶段一：水平扩展（日通知量 10 万 → 100 万）**

| 瓶颈 | 演进方案 |
|------|---------|
| 单实例处理能力 | 部署多个 Worker 实例，RabbitMQ 自动负载均衡 |
| MongoDB 写入压力 | 引入写入缓冲，批量写入；或使用 MongoDB 分片 |
| 单点故障 | RabbitMQ 集群化，MongoDB 副本集 |

**阶段二：高吞吐优化（日通知量 100 万 → 1000 万）**

| 瓶颈 | 演进方案 |
|------|---------|
| RabbitMQ 吞吐量 | 考虑迁移到 Kafka，支持更高吞吐和更好的分区能力 |
| 数据库查询压力 | 引入 Redis 缓存热点通知状态 |
| 监控数据量 | 指标聚合，减少 Prometheus 存储压力 |

**阶段三：复杂度增长时的演进方向**

| 新需求 | 演进方案 |
|--------|---------|
| 优先级队列 | 引入多个队列，按优先级分流 |
| 供应商级别限流 | 引入 Redis 令牌桶，按 vendor 限流 |
| 通知编排 | 引入工作流引擎（如 Temporal）处理复杂通知链 |
| 多租户隔离 | 按租户分队列，资源隔离 |

### 为什么 V1 不做这些？

1. **YAGNI 原则** - 在没有实际流量压力前，过早优化是浪费
2. **复杂度成本** - 分布式系统的复杂度会显著增加开发和运维成本
3. **验证业务价值** - V1 先验证业务需求是否正确，再考虑扩展性
4. **渐进式演进** - 当前架构预留了演进空间（如 Adapter 模式）



